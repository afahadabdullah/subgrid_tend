{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbdab06-e6e7-4ba7-bc4c-ab2c9411a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ce828b-124d-4ee5-9d67-b88b28c2f49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04d0e3-7e02-4592-9494-fc80b521e192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c8b05e-b224-4f84-bbec-15462af66509",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir='/css/g5nr/DYAMONDv2/GEOS_6km_Atmosphere-MITgcm_4km_Ocean-Coupled/GEOSgcm_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fee5434-471a-4c4e-8970-00de4ebc02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "odir='/home/afahad/nb/subgrid_tend/6km/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d03798b-b491-4e5f-861d-4476367638ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dir+'inst_01hr_3d_T_Mv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cbc7490-3dd9-40b5-abdf-ae264b483bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=sorted(glob('*.nc4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996d6b6b-2a07-42d5-a119-49864d96ed7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84a93cdd-270f-4cfd-8797-c2605d6e815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C90=xr.open_dataset('/home/afahad/nb/subgrid_tend/moist_internal_rst',decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4be7ee-4528-4bbe-842a-359bc1522ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "area=xr.open_dataset(dir+'const_2d_asm_Mx/DYAMOND_c1440_llc2160.const_2d_asm_Mx.20200122_0000z.nc4')[['AREA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6328d4-de51-4d28-8f53-44e617d5f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarsen_dataarray(da_in, area,  c5760_res=None,lon_c90=None, lat_c90=None):\n",
    "    \"\"\"\n",
    "    Coarsen a cubed-sphere DataArray from C5760 to C90 with area-weighted averaging.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    da_in : xr.DataArray\n",
    "        Input DataArray to be coarsened. Last two dimensions should be the spatial dimensions.\n",
    "    area : xr.DataArray or np.ndarray\n",
    "        Area weights array (should be the same shape as the spatial dimensions of da_in)\n",
    "    lon_c90 : array-like, optional\n",
    "        Longitude coordinates for the C90 grid. If None, will be created as a simple range.\n",
    "    lat_c90 : array-like, optional\n",
    "        Latitude coordinates for the C90 grid. If None, will be created as a simple range.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    xr.DataArray\n",
    "        Coarsened DataArray at C90 resolution\n",
    "    \"\"\"\n",
    "    # Define resolutions\n",
    "    c5760_res = 1440\n",
    "    c90_res = 90\n",
    "    factor = c5760_res // c90_res  # 64\n",
    "\n",
    "    original_dims = list(da_in.dims)\n",
    "    odims=list(da_in.dims)[:2]+['face', 'y', 'x']\n",
    "    \n",
    "    # Create default coordinates if not provided\n",
    "    if lon_c90 is None:\n",
    "        lon_c90 = np.arange(c90_res)\n",
    "    if lat_c90 is None:\n",
    "        lat_c90 = np.arange(6 * c90_res)  # 540 points across all 6 faces\n",
    "    \n",
    "    # Get original dimensions excluding the last two (spatial dimensions)\n",
    "    \n",
    "    \n",
    "    # Convert area to numpy if it's a DataArray\n",
    "    if isinstance(area, xr.DataArray):\n",
    "        area_data = area.values\n",
    "    else:\n",
    "        area_data = area\n",
    "    \n",
    "    # Reshape area to (6, 5760, 5760)\n",
    "    area_faces = area_data.reshape(6, c5760_res, c5760_res)\n",
    "    area_da = xr.DataArray(area_faces, dims=['face', 'y', 'x'])\n",
    "    \n",
    "    # Precompute coarsened areas\n",
    "    coarsened_area = area_da.coarsen(y=factor, x=factor, boundary='trim').sum()\n",
    "    \n",
    "    # Convert to 6*c90_res, c90_res shape for final output\n",
    "    area_c90 = coarsened_area.values.reshape(6 * c90_res, c90_res)\n",
    "    \n",
    "    # Reshape data to separate faces (preserve other dimensions)\n",
    "    if len(da_in.shape) > 3:\n",
    "        # Handle case with additional dimensions\n",
    "        #data_reshaped = da_in.values.reshape(da_in.shape[:-3] + (6, c5760_res, c5760_res))\n",
    "        data_reshaped = da_in.values.reshape( da_in.shape[:-2] + (6, c5760_res, c5760_res) )\n",
    "    else:\n",
    "        # Handle case with only spatial dimensions\n",
    "        data_reshaped = da_in.values.reshape(6, c5760_res, c5760_res)\n",
    "    \n",
    "    # Create temporary DataArray with face/y/x dims\n",
    "    if len(da_in.shape) > 3:\n",
    "        da_faces = xr.DataArray(\n",
    "            data_reshaped,\n",
    "            dims=original_dims[:-2] + ['face', 'y', 'x'],\n",
    "            attrs=da_in.attrs\n",
    "        )\n",
    "    else:\n",
    "        da_faces = xr.DataArray(\n",
    "            data_reshaped,\n",
    "            dims=['face', 'y', 'x'],\n",
    "            attrs=da_in.attrs\n",
    "        )\n",
    "    \n",
    "    # Area-weighted averaging\n",
    "    numerator = (da_faces * area_da).coarsen(y=factor, x=factor, boundary='trim').sum()\n",
    "    denominator = coarsened_area\n",
    "    result = (numerator / denominator).values\n",
    "    \n",
    "    # Reshape to final C90 dimensions\n",
    "    if len(da_in.shape) > 3:\n",
    "        #result_reshaped = result.reshape(da_in.shape[:-3] + (6,  c90_res, c90_res))\n",
    "        result_reshaped = result.reshape( da_in.shape[:-2] + (6, c90_res, c90_res) )\n",
    "    else:\n",
    "        result_reshaped = result.reshape(6,  c90_res, c90_res)\n",
    "\n",
    "    # print(result_reshaped.shape)\n",
    "    # print(original_dims)\n",
    "    # Build new DataArray\n",
    "    #print(odims, result_reshaped.shape)\n",
    "    return xr.DataArray(\n",
    "        result_reshaped,\n",
    "        dims=odims,\n",
    "        # coords={'lat': lat_c90, 'lon': lon_c90},\n",
    "        attrs=da_in.attrs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd6da4-7151-42ad-879f-7961f89034a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db1b064-bd8c-4f07-9551-a37e89762d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c2a25af-80da-4626-a97c-ad1930a13826",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 201/202 [1:42:46<00:30, 30.68s/it]  \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d2e042645b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mds1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.QV#.sel(lev=int(l))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mds2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_mfdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.QV.sel(lev=int(l))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mdT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mds1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mdT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoarsen_dataarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# create Hres dprdt\n",
    "files=files[188+596:]\n",
    "for i in tqdm(range(len(files))):\n",
    "            ds1=xr.open_mfdataset(files[i])#.QV#.sel(lev=int(l))\n",
    "            ds2=xr.open_mfdataset(files[i+1])#.QV.sel(lev=int(l))\n",
    "            dT=ds2.T.data-ds1.T.compute()\n",
    "            dT=coarsen_dataarray(dT,area.AREA)\n",
    "            dT.rename('dT').to_netcdf(odir+'dT_'+files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1813c5d4-5941-40d2-95c4-fb284085d7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff855f-1af2-41a9-9cd5-e126690d90dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4018cfc-6c1d-493a-9732-045997da2b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 890/890 [3:20:29<00:00, 13.52s/it]  \n"
     ]
    }
   ],
   "source": [
    "# create C90 of pr\n",
    "files=files[383:]\n",
    "for i in tqdm(range(len(files))):\n",
    "    ds1=xr.open_dataset(files[i])\n",
    "    pr=ds1.T\n",
    "    pr=coarsen_dataarray(pr,area.AREA)#,lon_c90=C90.lon,lat_c90=C90.lat)\n",
    "    pr.rename('T').to_netcdf(odir+'C90T_'+files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f43b843-9d1a-4f01-abd7-f5e4dd6ae972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "a1cae652-4932-4f57-a8ea-c3c2c18ff0bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66735d-9c2f-41a9-b88f-e4e936281bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333a8c7-cc9f-4002-a824-aef7b51c6386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a4d9f-2c27-479f-b57a-ad9782571bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:earthml]",
   "language": "python",
   "name": "conda-env-earthml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
